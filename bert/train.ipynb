{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea05286",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# --- Step 1. Load dataset ---\n",
    "df = pd.read_csv(\"/content/masterList.csv\")\n",
    "df = df.dropna(subset=[\"text\", \"label\"])\n",
    "df[\"label\"] = df[\"label\"].astype(int)   # force integer labels\n",
    "\n",
    "dataset = Dataset.from_pandas(df[[\"text\", \"label\"]])\n",
    "\n",
    "# --- Step 2. Train/validation split ---\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e610c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 3. Tokenizer ---\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace09424",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "eval_dataset  = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Force label dtype to int for both splits\n",
    "train_dataset = train_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
    "eval_dataset  = eval_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd206ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 4. Class weights (moderate) ---\n",
    "class_weights = torch.tensor([1.0, 1.3, 1.4, 1.5], dtype=torch.float).to(\"cuda\")\n",
    "\n",
    "# Weighted loss\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc0920",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 5. Load Model ---\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=4\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfa469",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 7. Custom Trainer ---\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\").to(torch.long)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ccb71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 8. Training arguments ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",     # <--- disables wandb\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# --- Step 9. Trainer ---\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,  # future-proof\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# --- Step 10. Train ---\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221325ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 11. Evaluate ---\n",
    "predictions = trainer.predict(eval_dataset)\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=[\"Valid (0)\", \"Spam (1)\", \"LowQuality (2)\", \"Rant (3)\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd17db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 12. Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3])\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Valid (0)\", \"Spam (1)\", \"LowQuality (2)\", \"Rant (3)\"],\n",
    "            yticklabels=[\"Valid (0)\", \"Spam (1)\", \"LowQuality (2)\", \"Rant (3)\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
